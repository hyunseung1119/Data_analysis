"""
LawExpertAgent - ë²•ë ¹ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸

ë²•ë ¹ ê²€ìƒ‰ ë° í•´ì„ì„ ë‹´ë‹¹í•˜ëŠ” ì „ë¬¸ê°€ ì—ì´ì „íŠ¸.
RAG ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ë²•ë ¹ì„ ì°¾ê³  í•´ì„í•©ë‹ˆë‹¤.
"""
from typing import Dict, Any
from ..base import BaseAgent, AgentInput, AgentOutput
from ..registry import AgentRegistry


@AgentRegistry.register("law_expert", config={
    "description": "ë²•ë ¹ ê²€ìƒ‰ ë° í•´ì„ ì „ë¬¸ê°€",
    "temperature": 0.2,
})
class LawExpertAgent(BaseAgent):
    """
    ë²•ë ¹ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸
    
    Responsibilities:
    - ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰ (RAG)
    - ì¡°ë¬¸ í•´ì„ ë° ì¸ìš©
    - íŒë¡€/í•´ì„ ì‚¬ë¡€ ì°¸ì¡°
    """
    
    def __init__(
        self, 
        name: str = "law_expert",
        description: str = "ë²•ë ¹ ê²€ìƒ‰ ë° í•´ì„ ì „ë¬¸ê°€",
        llm_service = None,
        config: Dict[str, Any] = None
    ):
        super().__init__(name, description, llm_service, config)
    
    def get_system_prompt(self) -> str:
        return """ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì„¸ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê´€ë ¨ ë²•ë ¹ì„ ê²€ìƒ‰í•˜ê³  ì •í™•í•œ ì¡°ë¬¸ì„ ì¸ìš©í•˜ì—¬ ë²•ì  ê·¼ê±°ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.

ê·œì¹™:
- í•­ìƒ ë²•ë ¹ ê·¼ê±°ë¥¼ ëª…ì‹œ (ì˜ˆ: ì†Œë“ì„¸ë²• ì œXXì¡°)
- ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ "í™•ì¸ í•„ìš”"ë¡œ í‘œê¸°
- ìµœì‹  ë²•ë ¹ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€
- íŒë¡€ë‚˜ í•´ì„ ì‚¬ë¡€ê°€ ìˆìœ¼ë©´ í•¨ê»˜ ì¸ìš©

ì¶œë ¥ í˜•ì‹:
## ğŸ“œ ë²•ë ¹ ë¶„ì„

### ê´€ë ¨ ë²•ë ¹
[ë²•ë ¹ ëª©ë¡ ë° ì¡°ë¬¸ ë²ˆí˜¸]

### í•µì‹¬ ë‚´ìš©
[ìš”ì•½ ì„¤ëª…]

### ì ìš© ì¡°ê±´
[ì¡°ê±´ ë° ìš”ê±´ ì„¤ëª…]

### ì£¼ì˜ì‚¬í•­
[ì£¼ì˜í•´ì•¼ í•  ì ]
"""
    
    async def execute(self, input: AgentInput) -> AgentOutput:
        """ë²•ë ¹ ë¶„ì„ ì‹¤í–‰"""
        if not self.llm:
            return AgentOutput(
                agent_name=self.name,
                result="LLM ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                confidence=0.0,
                reasoning="LLM service not configured"
            )
        
        # ì´ì „ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        previous_context = ""
        if input.previous_results:
            for prev in input.previous_results:
                previous_context += f"\n[{prev.get('agent_name', 'Unknown')}]: {prev.get('result', '')[:500]}"
        
        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        user_prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ë²•ë ¹ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {input.query}

{f'ì´ì „ ë¶„ì„ ê²°ê³¼:{previous_context}' if previous_context else ''}

ë²•ë ¹ ê·¼ê±°ì™€ í•¨ê»˜ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”."""
        
        try:
            result = await self.llm.chat(
                system_prompt=self.get_system_prompt(),
                user_message=user_prompt
            )
            
            return AgentOutput(
                agent_name=self.name,
                result=result,
                confidence=0.85,
                reasoning="ë²•ë ¹ ê²€ìƒ‰ ë° ì¡°ë¬¸ ë¶„ì„ ì™„ë£Œ",
                sources=[{"type": "law_analysis", "query": input.query}],
                metadata={"agent_type": "law_expert"}
            )
            
        except Exception as e:
            return AgentOutput(
                agent_name=self.name,
                result=f"ë²•ë ¹ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                confidence=0.0,
                reasoning=f"Error: {str(e)}",
                metadata={"error": True}
            )
